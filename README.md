# Lucas Dixon, Research Scientist (iislucas.github.io)

I am a principal research scientist in Google DeepMind and co-lead of [PAIR](pair.withgoogle.com) (People and AI Research). I work on visualisation, interpretability and control of machine learning systems, and specifically language models.

Previously, I was Chief Scientist at [Jigsaw](https://jigsaw.google.com/) where I founded engineering and research. I've worked on projects in a range of topics including digital security, formal logic, machine learning, and data visualization.

Before Google, I completed his PhD and worked in [the DREAM group](https://www.research.ed.ac.uk/en/publications/the-history-of-the-dream-group) in [Informatics at the University of Edinburgh](https://informatics.ed.ac.uk/) on the automation of mathematical reasoning, and later worked on graphical languages applied to quantum information. 

I also helped run a [non-profit working towards more rational and informed discussion and decision making](https://web.archive.org/web/20180315194233/http://www.kenyersel.org/), and was a co-founder of [TheoryMine](https://www.theorymine.com/), a playful take on automating mathematical discovery. 

Outside of scientific advances, I like martial arts.

## My favorite of [my papers](https://scholar.google.com/citations?user=nDs3-TMAAAAJ&hl=en&oi=ao)

My taste differs the citation counts of my papers, so of the that research projects I've been involved in, here's my personal favorites and why (Chronological order, I'll add more later)... 

 * [Improving Neutral Point of View Text Generation through Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality Dataset] (https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nDs3-TMAAAAJ&sortby=pubdate&citation_for_view=nDs3-TMAAAAJ:8AbLer7MMksC) 2025 -- Parameter efficient methods, like LoRA, by selecting small parameter sizes, also provide a form of NL regularization that enables them to learn better with less over-fitting than full tuning methods. The result is an incredibly powerful small data regime (O(100) examples) for controlled generation that doesn't overfit. 
 * [Patchscopes](https://pair.withgoogle.com/explorables/patchscopes/) 2024 -- This is basically a kind of NeuroScience "Brain Survey" to understand what part of a model is doing what; but you can do something amazing with AI brains that you can't with animal: you can literally cut out part of a thought and insert it somewhere else. This provides an incredibly powerful way to think about and analyse the internal mechnaisms in a Transformer-based langauge model.
 * [Interactive prompt debugging with sequence salience](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nDs3-TMAAAAJ&sortby=pubdate&citation_for_view=nDs3-TMAAAAJ:WbkHhVStYXYC) 2024 -- highlights that saliency methods actually provide an impressively powerful way to debug prompts. I think this is the first use of interrpetability as a prompt-debugger.
 * [Grokking Explorable](https://pair.withgoogle.com/explorables/grokking/) 2023 -- Interactive visualization explaning the phenomena of Grokking, typically referring to the moment when a machine learning model changes from memorizing some data, to internalizaing the key pattern within the data: generalizing. One thing I particularly like about this work is that it finally managed to nail the actual internal mechanism being used to learn the problem. It's hard to really get that deep, and many efforts didn't manage to fully catch it, but I believe this one did.
 * [Interpretability illusions in the generalization of simplified models](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nDs3-TMAAAAJ&sortby=pubdate&citation_for_view=nDs3-TMAAAAJ:P5F9QuxV20EC) 2023 -- A fascinating negative result: interpretable models can look good in distribution, but the simpler interreptable model actually has a different algorithm and different behavior when you look on different data. Data has so many complex interacting biases, that knowing the simpler model is what's really happening is really hard.
